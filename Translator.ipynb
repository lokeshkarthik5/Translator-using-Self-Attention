{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to C:\\Users\\Karthik\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19568fbd9502452c80e74a6c2c381260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ec45c1a9c24322be4107424f282922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a84298ebf8f400bba548cb1c016cfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=51785.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=1193.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=1803.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset ted_hrlr_translate downloaded and prepared to C:\\Users\\Karthik\\tensorflow_datasets\\ted_hrlr_translate\\pt_to_en\\0.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[None]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE, padded_shapes=([None],[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8214, 1259,    5, ...,    0,    0,    0],\n",
       "        [8214,  299,   13, ...,    0,    0,    0],\n",
       "        [8214,   59,    8, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,   95,    3, ...,    0,    0,    0],\n",
       "        [8214, 5157,    1, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   18,   12, ...,    0,    0,    0],\n",
       "        [8087,  634,   30, ...,    0,    0,    0],\n",
       "        [8087,   16,   13, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   17, 4981, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0]], dtype=int64)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "    \n",
    "        assert d_model % self.num_heads == 0\n",
    "    \n",
    "        self.depth = d_model // self.num_heads\n",
    "    \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "    \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "    \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.0102 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.9584 Accuracy 0.0007\n",
      "Epoch 1 Batch 100 Loss 8.8633 Accuracy 0.0115\n",
      "Epoch 1 Batch 150 Loss 8.7593 Accuracy 0.0156\n",
      "Epoch 1 Batch 200 Loss 8.6353 Accuracy 0.0177\n",
      "Epoch 1 Batch 250 Loss 8.4852 Accuracy 0.0198\n",
      "Epoch 1 Batch 300 Loss 8.3118 Accuracy 0.0239\n",
      "Epoch 1 Batch 350 Loss 8.1256 Accuracy 0.0275\n",
      "Epoch 1 Batch 400 Loss 7.9440 Accuracy 0.0303\n",
      "Epoch 1 Batch 450 Loss 7.7790 Accuracy 0.0330\n",
      "Epoch 1 Batch 500 Loss 7.6314 Accuracy 0.0365\n",
      "Epoch 1 Batch 550 Loss 7.4941 Accuracy 0.0404\n",
      "Epoch 1 Batch 600 Loss 7.3640 Accuracy 0.0443\n",
      "Epoch 1 Batch 650 Loss 7.2402 Accuracy 0.0480\n",
      "Epoch 1 Batch 700 Loss 7.1227 Accuracy 0.0517\n",
      "Epoch 1 Loss 7.1182 Accuracy 0.0518\n",
      "Time taken for 1 epoch: 91.55825591087341 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 5.5336 Accuracy 0.1022\n",
      "Epoch 2 Batch 50 Loss 5.4531 Accuracy 0.1034\n",
      "Epoch 2 Batch 100 Loss 5.3877 Accuracy 0.1064\n",
      "Epoch 2 Batch 150 Loss 5.3443 Accuracy 0.1084\n",
      "Epoch 2 Batch 200 Loss 5.2990 Accuracy 0.1103\n",
      "Epoch 2 Batch 250 Loss 5.2596 Accuracy 0.1121\n",
      "Epoch 2 Batch 300 Loss 5.2195 Accuracy 0.1138\n",
      "Epoch 2 Batch 350 Loss 5.1863 Accuracy 0.1154\n",
      "Epoch 2 Batch 400 Loss 5.1558 Accuracy 0.1168\n",
      "Epoch 2 Batch 450 Loss 5.1258 Accuracy 0.1182\n",
      "Epoch 2 Batch 500 Loss 5.1019 Accuracy 0.1195\n",
      "Epoch 2 Batch 550 Loss 5.0740 Accuracy 0.1209\n",
      "Epoch 2 Batch 600 Loss 5.0461 Accuracy 0.1223\n",
      "Epoch 2 Batch 650 Loss 5.0229 Accuracy 0.1235\n",
      "Epoch 2 Batch 700 Loss 4.9979 Accuracy 0.1245\n",
      "Epoch 2 Loss 4.9976 Accuracy 0.1246\n",
      "Time taken for 1 epoch: 64.67285704612732 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 4.6348 Accuracy 0.1423\n",
      "Epoch 3 Batch 50 Loss 4.6128 Accuracy 0.1417\n",
      "Epoch 3 Batch 100 Loss 4.5946 Accuracy 0.1434\n",
      "Epoch 3 Batch 150 Loss 4.5896 Accuracy 0.1442\n",
      "Epoch 3 Batch 200 Loss 4.5752 Accuracy 0.1447\n",
      "Epoch 3 Batch 250 Loss 4.5582 Accuracy 0.1456\n",
      "Epoch 3 Batch 300 Loss 4.5464 Accuracy 0.1464\n",
      "Epoch 3 Batch 350 Loss 4.5382 Accuracy 0.1469\n",
      "Epoch 3 Batch 400 Loss 4.5262 Accuracy 0.1473\n",
      "Epoch 3 Batch 450 Loss 4.5130 Accuracy 0.1480\n",
      "Epoch 3 Batch 500 Loss 4.4992 Accuracy 0.1484\n",
      "Epoch 3 Batch 550 Loss 4.4869 Accuracy 0.1490\n",
      "Epoch 3 Batch 600 Loss 4.4732 Accuracy 0.1497\n",
      "Epoch 3 Batch 650 Loss 4.4608 Accuracy 0.1505\n",
      "Epoch 3 Batch 700 Loss 4.4469 Accuracy 0.1512\n",
      "Epoch 3 Loss 4.4464 Accuracy 0.1513\n",
      "Time taken for 1 epoch: 64.88383102416992 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.3010 Accuracy 0.1534\n",
      "Epoch 4 Batch 50 Loss 4.1562 Accuracy 0.1641\n",
      "Epoch 4 Batch 100 Loss 4.1531 Accuracy 0.1652\n",
      "Epoch 4 Batch 150 Loss 4.1427 Accuracy 0.1663\n",
      "Epoch 4 Batch 200 Loss 4.1249 Accuracy 0.1671\n",
      "Epoch 4 Batch 250 Loss 4.1030 Accuracy 0.1677\n",
      "Epoch 4 Batch 300 Loss 4.0922 Accuracy 0.1684\n",
      "Epoch 4 Batch 350 Loss 4.0758 Accuracy 0.1695\n",
      "Epoch 4 Batch 400 Loss 4.0590 Accuracy 0.1707\n",
      "Epoch 4 Batch 450 Loss 4.0444 Accuracy 0.1721\n",
      "Epoch 4 Batch 500 Loss 4.0298 Accuracy 0.1732\n",
      "Epoch 4 Batch 550 Loss 4.0145 Accuracy 0.1743\n",
      "Epoch 4 Batch 600 Loss 4.0021 Accuracy 0.1752\n",
      "Epoch 4 Batch 650 Loss 3.9857 Accuracy 0.1763\n",
      "Epoch 4 Batch 700 Loss 3.9710 Accuracy 0.1773\n",
      "Epoch 4 Loss 3.9704 Accuracy 0.1773\n",
      "Time taken for 1 epoch: 66.16056394577026 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.5051 Accuracy 0.1903\n",
      "Epoch 5 Batch 50 Loss 3.6051 Accuracy 0.1968\n",
      "Epoch 5 Batch 100 Loss 3.6036 Accuracy 0.1976\n",
      "Epoch 5 Batch 150 Loss 3.5977 Accuracy 0.1978\n",
      "Epoch 5 Batch 200 Loss 3.5901 Accuracy 0.1982\n",
      "Epoch 5 Batch 250 Loss 3.5922 Accuracy 0.1979\n",
      "Epoch 5 Batch 300 Loss 3.5829 Accuracy 0.1987\n",
      "Epoch 5 Batch 350 Loss 3.5680 Accuracy 0.1998\n",
      "Epoch 5 Batch 400 Loss 3.5607 Accuracy 0.2006\n",
      "Epoch 5 Batch 450 Loss 3.5535 Accuracy 0.2012\n",
      "Epoch 5 Batch 500 Loss 3.5447 Accuracy 0.2020\n",
      "Epoch 5 Batch 550 Loss 3.5361 Accuracy 0.2024\n",
      "Epoch 5 Batch 600 Loss 3.5226 Accuracy 0.2034\n",
      "Epoch 5 Batch 650 Loss 3.5143 Accuracy 0.2038\n",
      "Epoch 5 Batch 700 Loss 3.5040 Accuracy 0.2045\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Epoch 5 Loss 3.5039 Accuracy 0.2045\n",
      "Time taken for 1 epoch: 67.20058178901672 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.2803 Accuracy 0.2065\n",
      "Epoch 6 Batch 50 Loss 3.2202 Accuracy 0.2178\n",
      "Epoch 6 Batch 100 Loss 3.1917 Accuracy 0.2197\n",
      "Epoch 6 Batch 150 Loss 3.1944 Accuracy 0.2194\n",
      "Epoch 6 Batch 200 Loss 3.1792 Accuracy 0.2195\n",
      "Epoch 6 Batch 250 Loss 3.1738 Accuracy 0.2196\n",
      "Epoch 6 Batch 300 Loss 3.1658 Accuracy 0.2202\n",
      "Epoch 6 Batch 350 Loss 3.1614 Accuracy 0.2208\n",
      "Epoch 6 Batch 400 Loss 3.1577 Accuracy 0.2216\n",
      "Epoch 6 Batch 450 Loss 3.1512 Accuracy 0.2221\n",
      "Epoch 6 Batch 500 Loss 3.1453 Accuracy 0.2227\n",
      "Epoch 6 Batch 550 Loss 3.1392 Accuracy 0.2231\n",
      "Epoch 6 Batch 600 Loss 3.1340 Accuracy 0.2236\n",
      "Epoch 6 Batch 650 Loss 3.1297 Accuracy 0.2238\n",
      "Epoch 6 Batch 700 Loss 3.1239 Accuracy 0.2242\n",
      "Epoch 6 Loss 3.1234 Accuracy 0.2242\n",
      "Time taken for 1 epoch: 66.02035427093506 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.8134 Accuracy 0.2480\n",
      "Epoch 7 Batch 50 Loss 2.8206 Accuracy 0.2389\n",
      "Epoch 7 Batch 100 Loss 2.7871 Accuracy 0.2393\n",
      "Epoch 7 Batch 150 Loss 2.7954 Accuracy 0.2389\n",
      "Epoch 7 Batch 200 Loss 2.7911 Accuracy 0.2398\n",
      "Epoch 7 Batch 250 Loss 2.7829 Accuracy 0.2406\n",
      "Epoch 7 Batch 300 Loss 2.7810 Accuracy 0.2417\n",
      "Epoch 7 Batch 350 Loss 2.7736 Accuracy 0.2425\n",
      "Epoch 7 Batch 400 Loss 2.7690 Accuracy 0.2430\n",
      "Epoch 7 Batch 450 Loss 2.7629 Accuracy 0.2435\n",
      "Epoch 7 Batch 500 Loss 2.7573 Accuracy 0.2438\n",
      "Epoch 7 Batch 550 Loss 2.7508 Accuracy 0.2443\n",
      "Epoch 7 Batch 600 Loss 2.7443 Accuracy 0.2451\n",
      "Epoch 7 Batch 650 Loss 2.7409 Accuracy 0.2455\n",
      "Epoch 7 Batch 700 Loss 2.7374 Accuracy 0.2456\n",
      "Epoch 7 Loss 2.7370 Accuracy 0.2456\n",
      "Time taken for 1 epoch: 66.59716892242432 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.4890 Accuracy 0.2360\n",
      "Epoch 8 Batch 50 Loss 2.4061 Accuracy 0.2602\n",
      "Epoch 8 Batch 100 Loss 2.4342 Accuracy 0.2607\n",
      "Epoch 8 Batch 150 Loss 2.4349 Accuracy 0.2613\n",
      "Epoch 8 Batch 200 Loss 2.4367 Accuracy 0.2625\n",
      "Epoch 8 Batch 250 Loss 2.4316 Accuracy 0.2630\n",
      "Epoch 8 Batch 300 Loss 2.4211 Accuracy 0.2630\n",
      "Epoch 8 Batch 350 Loss 2.4172 Accuracy 0.2634\n",
      "Epoch 8 Batch 400 Loss 2.4135 Accuracy 0.2637\n",
      "Epoch 8 Batch 450 Loss 2.4133 Accuracy 0.2639\n",
      "Epoch 8 Batch 500 Loss 2.4116 Accuracy 0.2639\n",
      "Epoch 8 Batch 550 Loss 2.4086 Accuracy 0.2640\n",
      "Epoch 8 Batch 600 Loss 2.4066 Accuracy 0.2645\n",
      "Epoch 8 Batch 650 Loss 2.4069 Accuracy 0.2644\n",
      "Epoch 8 Batch 700 Loss 2.4063 Accuracy 0.2644\n",
      "Epoch 8 Loss 2.4063 Accuracy 0.2644\n",
      "Time taken for 1 epoch: 67.11744594573975 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.0571 Accuracy 0.2998\n",
      "Epoch 9 Batch 50 Loss 2.1433 Accuracy 0.2791\n",
      "Epoch 9 Batch 100 Loss 2.1278 Accuracy 0.2791\n",
      "Epoch 9 Batch 150 Loss 2.1384 Accuracy 0.2787\n",
      "Epoch 9 Batch 200 Loss 2.1453 Accuracy 0.2783\n",
      "Epoch 9 Batch 250 Loss 2.1481 Accuracy 0.2780\n",
      "Epoch 9 Batch 300 Loss 2.1512 Accuracy 0.2783\n",
      "Epoch 9 Batch 350 Loss 2.1523 Accuracy 0.2784\n",
      "Epoch 9 Batch 400 Loss 2.1554 Accuracy 0.2784\n",
      "Epoch 9 Batch 450 Loss 2.1582 Accuracy 0.2782\n",
      "Epoch 9 Batch 500 Loss 2.1624 Accuracy 0.2778\n",
      "Epoch 9 Batch 550 Loss 2.1630 Accuracy 0.2777\n",
      "Epoch 9 Batch 600 Loss 2.1635 Accuracy 0.2777\n",
      "Epoch 9 Batch 650 Loss 2.1647 Accuracy 0.2781\n",
      "Epoch 9 Batch 700 Loss 2.1660 Accuracy 0.2786\n",
      "Epoch 9 Loss 2.1661 Accuracy 0.2785\n",
      "Time taken for 1 epoch: 66.66713547706604 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 2.0589 Accuracy 0.2953\n",
      "Epoch 10 Batch 50 Loss 1.9273 Accuracy 0.2938\n",
      "Epoch 10 Batch 100 Loss 1.9381 Accuracy 0.2955\n",
      "Epoch 10 Batch 150 Loss 1.9425 Accuracy 0.2931\n",
      "Epoch 10 Batch 200 Loss 1.9486 Accuracy 0.2929\n",
      "Epoch 10 Batch 250 Loss 1.9514 Accuracy 0.2924\n",
      "Epoch 10 Batch 300 Loss 1.9570 Accuracy 0.2920\n",
      "Epoch 10 Batch 350 Loss 1.9568 Accuracy 0.2922\n",
      "Epoch 10 Batch 400 Loss 1.9586 Accuracy 0.2917\n",
      "Epoch 10 Batch 450 Loss 1.9624 Accuracy 0.2917\n",
      "Epoch 10 Batch 500 Loss 1.9686 Accuracy 0.2914\n",
      "Epoch 10 Batch 550 Loss 1.9708 Accuracy 0.2912\n",
      "Epoch 10 Batch 600 Loss 1.9739 Accuracy 0.2907\n",
      "Epoch 10 Batch 650 Loss 1.9790 Accuracy 0.2903\n",
      "Epoch 10 Batch 700 Loss 1.9829 Accuracy 0.2900\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
      "Epoch 10 Loss 1.9828 Accuracy 0.2900\n",
      "Time taken for 1 epoch: 67.80113530158997 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.6731 Accuracy 0.3013\n",
      "Epoch 11 Batch 50 Loss 1.7631 Accuracy 0.3029\n",
      "Epoch 11 Batch 100 Loss 1.7820 Accuracy 0.3033\n",
      "Epoch 11 Batch 150 Loss 1.7875 Accuracy 0.3030\n",
      "Epoch 11 Batch 200 Loss 1.7930 Accuracy 0.3025\n",
      "Epoch 11 Batch 250 Loss 1.7985 Accuracy 0.3014\n",
      "Epoch 11 Batch 300 Loss 1.8078 Accuracy 0.3013\n",
      "Epoch 11 Batch 350 Loss 1.8129 Accuracy 0.3005\n",
      "Epoch 11 Batch 400 Loss 1.8167 Accuracy 0.3002\n",
      "Epoch 11 Batch 450 Loss 1.8184 Accuracy 0.3006\n",
      "Epoch 11 Batch 500 Loss 1.8219 Accuracy 0.3002\n",
      "Epoch 11 Batch 550 Loss 1.8253 Accuracy 0.2998\n",
      "Epoch 11 Batch 600 Loss 1.8304 Accuracy 0.2995\n",
      "Epoch 11 Batch 650 Loss 1.8343 Accuracy 0.2994\n",
      "Epoch 11 Batch 700 Loss 1.8403 Accuracy 0.2989\n",
      "Epoch 11 Loss 1.8401 Accuracy 0.2989\n",
      "Time taken for 1 epoch: 67.10835695266724 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.6445 Accuracy 0.3037\n",
      "Epoch 12 Batch 50 Loss 1.6411 Accuracy 0.3098\n",
      "Epoch 12 Batch 100 Loss 1.6654 Accuracy 0.3106\n",
      "Epoch 12 Batch 150 Loss 1.6608 Accuracy 0.3084\n",
      "Epoch 12 Batch 200 Loss 1.6734 Accuracy 0.3074\n",
      "Epoch 12 Batch 250 Loss 1.6808 Accuracy 0.3073\n",
      "Epoch 12 Batch 300 Loss 1.6850 Accuracy 0.3072\n",
      "Epoch 12 Batch 350 Loss 1.6882 Accuracy 0.3075\n",
      "Epoch 12 Batch 400 Loss 1.6932 Accuracy 0.3071\n",
      "Epoch 12 Batch 450 Loss 1.6986 Accuracy 0.3072\n",
      "Epoch 12 Batch 500 Loss 1.7025 Accuracy 0.3062\n",
      "Epoch 12 Batch 550 Loss 1.7063 Accuracy 0.3058\n",
      "Epoch 12 Batch 600 Loss 1.7108 Accuracy 0.3056\n",
      "Epoch 12 Batch 650 Loss 1.7168 Accuracy 0.3054\n",
      "Epoch 12 Batch 700 Loss 1.7215 Accuracy 0.3053\n",
      "Epoch 12 Loss 1.7217 Accuracy 0.3053\n",
      "Time taken for 1 epoch: 67.05793762207031 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.5937 Accuracy 0.3209\n",
      "Epoch 13 Batch 50 Loss 1.5594 Accuracy 0.3177\n",
      "Epoch 13 Batch 100 Loss 1.5600 Accuracy 0.3165\n",
      "Epoch 13 Batch 150 Loss 1.5567 Accuracy 0.3173\n",
      "Epoch 13 Batch 200 Loss 1.5659 Accuracy 0.3169\n",
      "Epoch 13 Batch 250 Loss 1.5750 Accuracy 0.3170\n",
      "Epoch 13 Batch 300 Loss 1.5800 Accuracy 0.3156\n",
      "Epoch 13 Batch 350 Loss 1.5850 Accuracy 0.3149\n",
      "Epoch 13 Batch 400 Loss 1.5892 Accuracy 0.3149\n",
      "Epoch 13 Batch 450 Loss 1.5952 Accuracy 0.3148\n",
      "Epoch 13 Batch 500 Loss 1.6005 Accuracy 0.3145\n",
      "Epoch 13 Batch 550 Loss 1.6040 Accuracy 0.3139\n",
      "Epoch 13 Batch 600 Loss 1.6105 Accuracy 0.3135\n",
      "Epoch 13 Batch 650 Loss 1.6140 Accuracy 0.3135\n",
      "Epoch 13 Batch 700 Loss 1.6202 Accuracy 0.3126\n",
      "Epoch 13 Loss 1.6203 Accuracy 0.3126\n",
      "Time taken for 1 epoch: 67.09760975837708 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.5411 Accuracy 0.3424\n",
      "Epoch 14 Batch 50 Loss 1.4384 Accuracy 0.3254\n",
      "Epoch 14 Batch 100 Loss 1.4563 Accuracy 0.3239\n",
      "Epoch 14 Batch 150 Loss 1.4704 Accuracy 0.3224\n",
      "Epoch 14 Batch 200 Loss 1.4812 Accuracy 0.3227\n",
      "Epoch 14 Batch 250 Loss 1.4878 Accuracy 0.3222\n",
      "Epoch 14 Batch 300 Loss 1.4915 Accuracy 0.3221\n",
      "Epoch 14 Batch 350 Loss 1.4973 Accuracy 0.3219\n",
      "Epoch 14 Batch 400 Loss 1.5006 Accuracy 0.3210\n",
      "Epoch 14 Batch 450 Loss 1.5049 Accuracy 0.3206\n",
      "Epoch 14 Batch 500 Loss 1.5092 Accuracy 0.3202\n",
      "Epoch 14 Batch 550 Loss 1.5148 Accuracy 0.3194\n",
      "Epoch 14 Batch 600 Loss 1.5216 Accuracy 0.3187\n",
      "Epoch 14 Batch 650 Loss 1.5286 Accuracy 0.3183\n",
      "Epoch 14 Batch 700 Loss 1.5351 Accuracy 0.3178\n",
      "Epoch 14 Loss 1.5351 Accuracy 0.3179\n",
      "Time taken for 1 epoch: 67.24228572845459 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.3069 Accuracy 0.3619\n",
      "Epoch 15 Batch 50 Loss 1.3565 Accuracy 0.3312\n",
      "Epoch 15 Batch 100 Loss 1.3686 Accuracy 0.3309\n",
      "Epoch 15 Batch 150 Loss 1.3793 Accuracy 0.3294\n",
      "Epoch 15 Batch 200 Loss 1.3909 Accuracy 0.3285\n",
      "Epoch 15 Batch 250 Loss 1.3966 Accuracy 0.3284\n",
      "Epoch 15 Batch 300 Loss 1.4073 Accuracy 0.3284\n",
      "Epoch 15 Batch 350 Loss 1.4144 Accuracy 0.3277\n",
      "Epoch 15 Batch 400 Loss 1.4205 Accuracy 0.3261\n",
      "Epoch 15 Batch 450 Loss 1.4256 Accuracy 0.3254\n",
      "Epoch 15 Batch 500 Loss 1.4318 Accuracy 0.3250\n",
      "Epoch 15 Batch 550 Loss 1.4383 Accuracy 0.3248\n",
      "Epoch 15 Batch 600 Loss 1.4436 Accuracy 0.3245\n",
      "Epoch 15 Batch 650 Loss 1.4515 Accuracy 0.3238\n",
      "Epoch 15 Batch 700 Loss 1.4569 Accuracy 0.3233\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
      "Epoch 15 Loss 1.4575 Accuracy 0.3233\n",
      "Time taken for 1 epoch: 67.40565729141235 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.4452 Accuracy 0.3097\n",
      "Epoch 16 Batch 50 Loss 1.3044 Accuracy 0.3355\n",
      "Epoch 16 Batch 100 Loss 1.3121 Accuracy 0.3347\n",
      "Epoch 16 Batch 150 Loss 1.3309 Accuracy 0.3336\n",
      "Epoch 16 Batch 200 Loss 1.3377 Accuracy 0.3320\n",
      "Epoch 16 Batch 250 Loss 1.3394 Accuracy 0.3313\n",
      "Epoch 16 Batch 300 Loss 1.3482 Accuracy 0.3308\n",
      "Epoch 16 Batch 350 Loss 1.3536 Accuracy 0.3305\n",
      "Epoch 16 Batch 400 Loss 1.3562 Accuracy 0.3306\n",
      "Epoch 16 Batch 450 Loss 1.3626 Accuracy 0.3304\n",
      "Epoch 16 Batch 500 Loss 1.3705 Accuracy 0.3300\n",
      "Epoch 16 Batch 550 Loss 1.3760 Accuracy 0.3292\n",
      "Epoch 16 Batch 600 Loss 1.3830 Accuracy 0.3289\n",
      "Epoch 16 Batch 650 Loss 1.3876 Accuracy 0.3287\n",
      "Epoch 16 Batch 700 Loss 1.3929 Accuracy 0.3283\n",
      "Epoch 16 Loss 1.3927 Accuracy 0.3283\n",
      "Time taken for 1 epoch: 67.06873846054077 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.2205 Accuracy 0.3525\n",
      "Epoch 17 Batch 50 Loss 1.2544 Accuracy 0.3377\n",
      "Epoch 17 Batch 100 Loss 1.2588 Accuracy 0.3363\n",
      "Epoch 17 Batch 150 Loss 1.2607 Accuracy 0.3373\n",
      "Epoch 17 Batch 200 Loss 1.2733 Accuracy 0.3354\n",
      "Epoch 17 Batch 250 Loss 1.2830 Accuracy 0.3349\n",
      "Epoch 17 Batch 300 Loss 1.2890 Accuracy 0.3348\n",
      "Epoch 17 Batch 350 Loss 1.2943 Accuracy 0.3346\n",
      "Epoch 17 Batch 400 Loss 1.3005 Accuracy 0.3346\n",
      "Epoch 17 Batch 450 Loss 1.3061 Accuracy 0.3346\n",
      "Epoch 17 Batch 500 Loss 1.3123 Accuracy 0.3344\n",
      "Epoch 17 Batch 550 Loss 1.3182 Accuracy 0.3340\n",
      "Epoch 17 Batch 600 Loss 1.3228 Accuracy 0.3332\n",
      "Epoch 17 Batch 650 Loss 1.3269 Accuracy 0.3328\n",
      "Epoch 17 Batch 700 Loss 1.3315 Accuracy 0.3322\n",
      "Epoch 17 Loss 1.3316 Accuracy 0.3323\n",
      "Time taken for 1 epoch: 67.22282099723816 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.1050 Accuracy 0.3363\n",
      "Epoch 18 Batch 50 Loss 1.1908 Accuracy 0.3448\n",
      "Epoch 18 Batch 100 Loss 1.2069 Accuracy 0.3408\n",
      "Epoch 18 Batch 150 Loss 1.2161 Accuracy 0.3427\n",
      "Epoch 18 Batch 200 Loss 1.2232 Accuracy 0.3415\n",
      "Epoch 18 Batch 250 Loss 1.2306 Accuracy 0.3414\n",
      "Epoch 18 Batch 300 Loss 1.2366 Accuracy 0.3402\n",
      "Epoch 18 Batch 350 Loss 1.2440 Accuracy 0.3390\n",
      "Epoch 18 Batch 400 Loss 1.2480 Accuracy 0.3386\n",
      "Epoch 18 Batch 450 Loss 1.2517 Accuracy 0.3381\n",
      "Epoch 18 Batch 500 Loss 1.2579 Accuracy 0.3377\n",
      "Epoch 18 Batch 550 Loss 1.2620 Accuracy 0.3370\n",
      "Epoch 18 Batch 600 Loss 1.2674 Accuracy 0.3364\n",
      "Epoch 18 Batch 650 Loss 1.2737 Accuracy 0.3361\n",
      "Epoch 18 Batch 700 Loss 1.2784 Accuracy 0.3359\n",
      "Epoch 18 Loss 1.2785 Accuracy 0.3359\n",
      "Time taken for 1 epoch: 66.69436764717102 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.1889 Accuracy 0.3366\n",
      "Epoch 19 Batch 50 Loss 1.1507 Accuracy 0.3468\n",
      "Epoch 19 Batch 100 Loss 1.1534 Accuracy 0.3479\n",
      "Epoch 19 Batch 150 Loss 1.1605 Accuracy 0.3469\n",
      "Epoch 19 Batch 200 Loss 1.1682 Accuracy 0.3443\n",
      "Epoch 19 Batch 250 Loss 1.1727 Accuracy 0.3442\n",
      "Epoch 19 Batch 300 Loss 1.1816 Accuracy 0.3442\n",
      "Epoch 19 Batch 350 Loss 1.1891 Accuracy 0.3432\n",
      "Epoch 19 Batch 400 Loss 1.1937 Accuracy 0.3433\n",
      "Epoch 19 Batch 450 Loss 1.1986 Accuracy 0.3430\n",
      "Epoch 19 Batch 500 Loss 1.2040 Accuracy 0.3422\n",
      "Epoch 19 Batch 550 Loss 1.2109 Accuracy 0.3420\n",
      "Epoch 19 Batch 600 Loss 1.2172 Accuracy 0.3411\n",
      "Epoch 19 Batch 650 Loss 1.2223 Accuracy 0.3409\n",
      "Epoch 19 Batch 700 Loss 1.2284 Accuracy 0.3405\n",
      "Epoch 19 Loss 1.2287 Accuracy 0.3405\n",
      "Time taken for 1 epoch: 67.34420585632324 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.0614 Accuracy 0.3552\n",
      "Epoch 20 Batch 50 Loss 1.0981 Accuracy 0.3495\n",
      "Epoch 20 Batch 100 Loss 1.1023 Accuracy 0.3500\n",
      "Epoch 20 Batch 150 Loss 1.1118 Accuracy 0.3498\n",
      "Epoch 20 Batch 200 Loss 1.1252 Accuracy 0.3483\n",
      "Epoch 20 Batch 250 Loss 1.1300 Accuracy 0.3478\n",
      "Epoch 20 Batch 300 Loss 1.1326 Accuracy 0.3478\n",
      "Epoch 20 Batch 350 Loss 1.1422 Accuracy 0.3469\n",
      "Epoch 20 Batch 400 Loss 1.1481 Accuracy 0.3471\n",
      "Epoch 20 Batch 450 Loss 1.1532 Accuracy 0.3468\n",
      "Epoch 20 Batch 500 Loss 1.1601 Accuracy 0.3460\n",
      "Epoch 20 Batch 550 Loss 1.1660 Accuracy 0.3454\n",
      "Epoch 20 Batch 600 Loss 1.1735 Accuracy 0.3447\n",
      "Epoch 20 Batch 650 Loss 1.1796 Accuracy 0.3444\n",
      "Epoch 20 Batch 700 Loss 1.1844 Accuracy 0.3436\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n",
      "Epoch 20 Loss 1.1844 Accuracy 0.3437\n",
      "Time taken for 1 epoch: 68.04021906852722 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to solve .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
